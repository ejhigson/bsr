{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Results Testing\n",
    "\n",
    "Notebook for creating results tables and plots and testing them interactively. Note that the plots are also made by ``compute_results.py``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nestcheck.ns_run_utils\n",
    "import bsr.data\n",
    "import bsr.likelihoods\n",
    "import bsr.basis_functions as bf\n",
    "import bsr.neural_networks as nn\n",
    "import bsr.plotting\n",
    "import bsr.results_utils\n",
    "import bsr.results_tables\n",
    "import bsr.paper_plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings\n",
    "\n",
    "Specify the problem. See ``compute_results.py`` for an explanation of the settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and function to fit it with\n",
    "# --------------------------------\n",
    "fit_func_list = [bf.gg_1d]\n",
    "data_func_list = [bf.gg_1d]\n",
    "data_type_list = [3]\n",
    "inds = list(range(1, 6))  # run indexes to use\n",
    "# Method to use\n",
    "# -------------\n",
    "# for 1d data\n",
    "method_tups_1d = [(False, None, 200, 100),\n",
    "                  (True, None, 1000, 100),\n",
    "                  (True, 1, 1000, 100)]\n",
    "# for 2d data\n",
    "method_tups_2d = [(False, None, 400, 250),\n",
    "                  (True, None, 2000, 250),\n",
    "                  (True, 1, 2000, 250)]\n",
    "# Set up\n",
    "# ------\n",
    "problem_tups = []\n",
    "for fit_func in fit_func_list:\n",
    "    for data_func in data_func_list:\n",
    "        for data_type in data_type_list:\n",
    "            problem_tups.append((fit_func, data_func, data_type))\n",
    "method_tups = method_tups_1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "# ---------\n",
    "load_data = True\n",
    "if load_data:\n",
    "    # Load the NS runs\n",
    "    results_dict = bsr.results_utils.load_data(\n",
    "        problem_tups, method_tups, inds, base_dir='chains')\n",
    "else:\n",
    "    # Just get a dictionary of information on the likelihoods\n",
    "    # Can be used to load cached results tables without loading all the NS runs\n",
    "    results_dict = bsr.results_utils.make_base_dict(problem_tups, method_tups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results tables\n",
    "# ------------------\n",
    "results_df = bsr.results_tables.get_results_df(\n",
    "    results_dict, load=True, n_simulate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check T posterior\n",
    "# # -----------------\n",
    "# results_df['$P(T=1)$'].xs('True_1_2000_250', level='method key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make LaTeX results table\n",
    "# ------------------------\n",
    "# Paper uses estimator = ['$y(0.5)$'] for 1d and['$y(0.5,0.5)$'] for 2d\n",
    "estimator = ['$y(0.5)$']\n",
    "calc_types = ['combined', 'bs gain']\n",
    "# get df\n",
    "df_temp = results_df.loc[pd.IndexSlice[:, :, calc_types, :], :][estimator].unstack('method key') #['$P(N=1)$'].unstack('method key')\n",
    "# add number of samples\n",
    "df_temp_nsamp = results_df.loc[pd.IndexSlice[:, :, ['combined'], ['value']], :]['nsample'].unstack('method key')\n",
    "for pk in set(df_temp.index.get_level_values('problem key')):\n",
    "    df_temp.loc[(pk, '\\# samples', 'value'), :] = df_temp_nsamp.loc[(pk, 'combined', 'value'), :].values\n",
    "# add true value\n",
    "df_temp ['true value'] = np.nan\n",
    "for pk in set(df_temp.index.get_level_values('problem key')):\n",
    "    df_temp.loc[(pk, 'combined', 'value'), 'true value'] = bsr.data.get_true_value(\n",
    "        bf.gg_1d, int(pk[-1]))\n",
    "cols = ['vanilla', 'dynamic adaptive', 'adaptive', 'true value']\n",
    "df_temp.columns = cols\n",
    "df_temp.loc[pd.IndexSlice[:, ['bs gain'], :], ['vanilla']] = np.nan\n",
    "df_temp = df_temp[[cols[i] for i in [0, 2, 1]]]\n",
    "df_temp = df_temp.sort_index()\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_map = {'combined': r'$y(0.5;\\bm{\\theta})$',\n",
    "           'bs gain': 'efficiency gain',\n",
    "           'NaN': ''}\n",
    "try:\n",
    "    import texunc\n",
    "    df_tex = texunc.print_latex_df(\n",
    "        df_temp,\n",
    "        min_dp=0, max_dp=4, max_power=5, str_map=str_map)\n",
    "    df_tex\n",
    "except ImportError:\n",
    "    print(\"Install texunc for LaTeX formatting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Odds\n",
    "# ---------\n",
    "odds_fig_list = bsr.paper_plots.odds(\n",
    "    results_df, max_unc=True, nruns=len(inds)) # .xs('gg_1d_gg_1d_1', drop_level=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot multi\n",
    "# ----------\n",
    "multi_fig_list = bsr.paper_plots.multi(\n",
    "    results_dict,\n",
    "    prob_condition=lambda x: True,  # x == ('gg_2d', 'gg_2d', 1),\n",
    "    meth_condition=lambda x: True)  # x[0] and x[1] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot split\n",
    "# ----------\n",
    "import bsr.plotting\n",
    "plt.close('all')\n",
    "split_fig_list = bsr.paper_plots.split(\n",
    "    results_dict,\n",
    "    prob_condition=lambda x: True,  # x == ('gg_2d', 'get_image', 1),  # ((x[0] == 'nn_1l' and x[1] == 'get_image') and x[1] or 'adfam' in x[0]) and x[2] == 1,\n",
    "    meth_condition=lambda x: not x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra plots not used in paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data_func in [bf.gg_1d]:  # [bsr.data.get_image, bf.gg_2d]:\n",
    "    if data_func.__name__[-2:] == '1d':\n",
    "        y_error_sigma = 0.075\n",
    "        x_error_sigma = 0.075\n",
    "        npoints = 100\n",
    "    else:\n",
    "        y_error_sigma = 0.3\n",
    "        x_error_sigma = None\n",
    "        npoints = 32\n",
    "    for data_type in [1, 2, 3]:\n",
    "        fig = bsr.plotting.plot_runs(\n",
    "            [], [], data=bsr.data.generate_data(data_func, data_type, y_error_sigma, x_error_sigma=x_error_sigma, npoints=npoints),\n",
    "            plot_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Prior Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_likelihood = bsr.likelihoods.FittingLikelihood(\n",
    "    bsr.data.generate_data(bf.gg_1d, 1, 0.1), bf.gg_1d, 10,  # NB number of funcs may affect prior plot\n",
    "    adaptive=True)\n",
    "prior_fig = bsr.plotting.plot_prior(temp_likelihood, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getdist plot\n",
    "\n",
    "This requires ``getdist``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getdist.plots\n",
    "prob_key = ('gg_1d', 'gg_1d', 3)\n",
    "meth_key = method_tups[0]\n",
    "print(meth_key)\n",
    "nfunc = 3\n",
    "likelihood = results_dict[prob_key][meth_key]['likelihood_list'][0 if meth_key[0] else nfunc - 1]\n",
    "run = results_dict[prob_key][meth_key]['run_list'][0 if meth_key[0] else nfunc - 1]\n",
    "\n",
    "names = likelihood.get_param_names()\n",
    "print(names)\n",
    "latex_names = [name[1:-1] for name in likelihood.get_param_latex_names()]\n",
    "print(latex_names)\n",
    "logw = nestcheck.ns_run_utils.get_logw(run)\n",
    "weights = np.exp(logw - logw.max())\n",
    "# remove zero weights as they can throw errors\n",
    "inds = np.nonzero(weights)\n",
    "samples = getdist.MCSamples(\n",
    "    samples=run['theta'][inds, :], weights=weights[inds],\n",
    "    names=names,\n",
    "    labels=latex_names,\n",
    "    label='run')\n",
    "g = getdist.plots.getSubplotPlotter()\n",
    "g.triangle_plot(samples, names, shaded=True)"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}